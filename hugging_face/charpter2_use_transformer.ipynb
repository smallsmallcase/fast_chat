{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecb01c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: POSITIVE, with score: 0.9598051\n",
      "label: NEGATIVE, with score: 0.9994559\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "result = classifier(\n",
    "    [\n",
    "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "        \"I hate this so much!\",\n",
    "    ]\n",
    ")\n",
    "for r in result:\n",
    "    print(f\"label: {r['label']}, with score: {round(r['score'], 7)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ddc4933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 接下来是复刻管道的多个步骤，按照三个步骤分开执行\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b54a6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
      "          2607,  2026,  2878,  2166,  1012,   102],\n",
      "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5580,  2000,  2156,  2017,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2293,  2017,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  5580,  2000,  2182,  2008,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,   100,  1811,  1811,   100,   100,   100,   100,  1989,   100,\n",
      "          1744,   100,   100,   102,     0,     0]])\n",
      "attention_mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\",\n",
    "    \"glad to see you\",\n",
    "    \"i love you\",\n",
    "    \"glad to here that\",\n",
    "    \"今天天气好热啊，受不了了\"\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "for key, value in inputs.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "# print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ca5887c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 16, 768])\n"
     ]
    }
   ],
   "source": [
    "# explore model\n",
    "from transformers import AutoModel\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModel.from_pretrained(checkpoint)\n",
    "\n",
    "my_model_outputs = model(**inputs)\n",
    "print(my_model_outputs.last_hidden_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ea7703d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2])\n",
      "tensor([[-1.5607,  1.6123],\n",
      "        [ 4.1692, -3.3464],\n",
      "        [-4.1307,  4.5048],\n",
      "        [-4.2756,  4.6393],\n",
      "        [-3.8654,  4.1883],\n",
      "        [ 1.1069, -0.9462]], grad_fn=<AddmmBackward0>)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "outputs = model(**inputs)\n",
    "print(outputs.logits.shape)  # (batch_size, sequence_length, hidden_size)\n",
    "print(outputs.logits)\n",
    "print(outputs.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae5058a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.0195e-02, 9.5981e-01],\n",
      "        [9.9946e-01, 5.4418e-04],\n",
      "        [1.7765e-04, 9.9982e-01],\n",
      "        [1.3436e-04, 9.9987e-01],\n",
      "        [3.1781e-04, 9.9968e-01],\n",
      "        [8.8626e-01, 1.1374e-01]], grad_fn=<SoftmaxBackward0>)\n",
      "{0: 'NEGATIVE', 1: 'POSITIVE'}\n",
      "Sentence 0 is positive with score 0.9598\n",
      "Sentence 1 is negative with score 0.9995\n",
      "Sentence 2 is positive with score 0.9998\n",
      "Sentence 3 is positive with score 0.9999\n",
      "Sentence 4 is positive with score 0.9997\n",
      "Sentence 5 is negative with score 0.8863\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "print(predictions)\n",
    "print(model.config.id2label)\n",
    "for i, pred in enumerate(predictions):\n",
    "    if pred[0] > pred[1]:\n",
    "        print(f\"Sentence {i} is negative with score {pred[0]:.4f}\")\n",
    "    else:\n",
    "        print(f\"Sentence {i} is positive with score {pred[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2368116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.53.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use model\n",
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "# 初始化 Config 类\n",
    "config = BertConfig()\n",
    "print(config)\n",
    "# 如果想要加载预训练模型，可以使用 `from_pretrained` 方法\n",
    "# config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "# 这里使用默认的配置参数初始化 BertModel\n",
    "# model = BertModel(config)\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\") # 加载预训练模型\n",
    "model.save_pretrained(\"my_bert_model\")  # 保存模型到本地\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba4b974e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jim', 'Henson', 'was', 'a', 'puppeteer']\n"
     ]
    }
   ],
   "source": [
    "## begin tokenizer\n",
    "text = \"Jim Henson was a puppeteer\"\n",
    "tokenized_text = text.split()\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92a81d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d95b028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: tensor([[  101, 19082,  1362,   102,     0,     0,     0,     0,     0,     0]])\n",
      "token_type_ids: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "attention_mask: tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "result = tokenizer(\"hello world\",padding='max_length', max_length=10, return_tensors=\"pt\")\n",
    "for key, value in result.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6fd39ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Using', 'a', 'Trans', '##former', 'network', 'is', 'simple']\n",
      "[7993, 170, 13809, 23763, 2443, 1110, 3014]\n"
     ]
    }
   ],
   "source": [
    "# 单独tokenize\n",
    "sequence = \"Using a Transformer network is simple\"\n",
    "token = tokenizer.tokenize(sequence)  # 分词\n",
    "print(token)  # ['Using', 'a', 'Transformer', 'network', 'is', 'simple'\n",
    "ids = tokenizer.convert_tokens_to_ids(token)  # 转换为ID\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d15f3a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer network is simple\n"
     ]
    }
   ],
   "source": [
    "decoded_str = tokenizer.decode(ids)  # 转换回token\n",
    "print(decoded_str)  # Using a Transformer network is simple"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
